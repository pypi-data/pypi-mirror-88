Metadata-Version: 2.1
Name: npu-compiler
Version: 1.5.3rc6
Summary: produce NPU instructions
Home-page: http://ai.nationalchip.com/
Author: Hangzhou Nationalchip Inc.
Author-email: zhengdi@nationalchip.com
License: MIT Licence
Keywords: npu gxdnn nationalchip
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.6
Requires-Dist: numpy
Requires-Dist: pyyaml
Requires-Dist: wheel
Requires-Dist: six
Requires-Dist: humanize
Requires-Dist: prettytable
Requires-Dist: scipy

# NPU compiler

produce NPU instructions

## Release Notes

### Release 1.5.2
  - GRUS芯片不再支持Maximum和Minimum.
  - GRUS芯片生成的.h文件中增加in_out结构体。
  - GRUS芯片增加AddV2,BatchMatMulV2,FusedBatchNorm.
  - GRUS芯片优化量化方法，减少量化损失。
  - GRUS芯片配置文件增加配置项FUSE_BN，可配置是否把BN参数合并到卷积中，默认不合并。
  - BUG修复。

### Release 1.5.1
  - GRUS芯片卷积权重默认不压缩，如需压缩，配置文件中指定CONV2D_COMPRESS: true
  - 增加Python版本的判断，目前支持Python2.7和Python3.6，不是这些版本则报错。
  - 解决Python3安装包在conda环境下安装后，报"undefined symbol: PyFPE_jbuf"的问题。
  - GRUS芯片增加Pad OP
  - GRUS芯片支持MaxPool和AvgPool的kernel_h或kernel_w为1的情况。
  - GRUS芯片模型编译后增加NPU Size的打印信息。
  - GRUS芯片优化depthwise_conv2d的内存。

### Release 1.5.0
  - 增加GRUS芯片的支持。

### Release 1.0.17
  - 优化Transpose,MatMul的计算。
  - BUG修复。

### Release 1.0.16
  - 配置文件中增加MODEL_INFO字段，可加入用户自定义的模型信息，编译完后该信息和编译时间会加入到npu文件中。
  - 优化了Conv2d和DepthwiseConv2d NCHW 1*1卷积核的计算。
  - 支持空洞卷积（tf.layers.Conv2D中dilation大于1）。
  - BUG修复。

### Release 1.0.15
  - 增加OP：Relu6, GatherV2
  - 支持SNPU的ReverseV2 OP
  - 合并DepthwiseConv2d和Add/BiasAdd运算，优化BiasAdd，提高Rsqrt的精度，优化prelu
  - 整合了tensorflow的inference优化脚本，如果模型中的FusedBatchNorm OP前是Conv2D或DepthwiseConv2d，FusedBatchNorm会优化成BiasAdd
  - gxnpuc增加-m选项，编译模式时加上该选项可以打印出各个OP的内存信息。
  - BUG修复。

### Release 1.0.14
  - 增加OP： ListDiff，Abs
  - 支持Tile运行时计算
  - 优化Concat，Reduce类OP（如Sum, Mean）的计算，节省BatchMatMul的内存空间
  - 支持命令行读取配置参数，如 cat config.yaml | gxnpuc
  - Bug修复。

### Release 1.0.13
  - 支持Select OP
  - 加快生成c_code模型的速度。
  - 优化SNPU的1*1卷积，转置，减少生成指令大小。
  - 增加MEAN_SHRINK_OPS配置项，容易溢出的Mean OP放在该列表中，NPU会先做除法再做加法。
  - 生成的模型中增加需要内存总大小：total_size字段。
  - BUG修复。

### Release 1.0.12
  - 支持新版本TensorFlow的模型有些OP在其输入OP后面的情况。
  - 优化1*1的卷积，能减少大量指令，提高执行效率。
  - 优化Transpose OP
  - 增加模型中间数据的复用，减少模型需要的内存。
  - BUG修复。

### Release 1.0.11
  - 增加了DepthwiseConv2dNative，AvgPool， Conv2DBackpropInput， Maximum， Minimum， GreaterEqual， LessEqual， Assert， Tile， All， Any， BatchMatMul， ReverseV2， Exp
  - 支持做MatMul时，权重（第二个输入数据）在编译阶段不确定的情况。
  - BUG修复。

### Release 1.0.10
  - 对Conv2D, Slice等OP的优化。
  - 增加了Max, Min, FloorDiv, FloorMod OP
  - 增加了空间优化的选项，可以根据模型时间敏感还是空间敏感来配置。配置项为 SPACE_OPTIMIZATION：0/1  数字越大表示需要内存空间越小，相应速度会慢，目前只支持0或1。目前只有Conv2D, Slice OP在某些条件下会起作用。
  - BUG修复。

### Release 1.0.9
  - 针对NPU硬件的问题增加了补丁。
  - 优化了Mean, Sum, Conv2D等OP
  - 增加对1x1卷积核的支持。
  - BUG修复。

### Release 1.0.8 (空缺)

### Release 1.0.7
  - 配置文件中可以任意指定输出OP，不执行和输出OP无关的OP
  - 增加LogSoftmax OP
  - OP优化和BUG修复

### Release 1.0.6
  - 配置文件增加新配置项 CORENAME，可以选择 LEO 或 LEO_MPE，默认为 LEO
  - 对OP log 和 softmax 合并在一起计算，减少计算误差。
  - 加速多 batch LSTM计算，加速归一化计算。
  - 参数 fp32 转 fp16 由截位变成四舍五入。
  - bug 修复。



