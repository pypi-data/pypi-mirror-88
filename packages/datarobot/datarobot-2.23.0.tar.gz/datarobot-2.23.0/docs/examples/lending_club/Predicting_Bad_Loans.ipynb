{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bad Loans\n",
    "\n",
    "## Overview\n",
    "In this example we will build a binary classification model using the Lending Club dataset.\n",
    "Here is a list of things we will touch on during this notebook:\n",
    "\n",
    "- Installing the `datarobot` package\n",
    "- Configuring the client\n",
    "- Creating a project\n",
    "- Changing the datatype of some of the source columns\n",
    "- Selecting the source columns used in the modeling process\n",
    "- Running the automated modeling process\n",
    "- Generating predictions\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "In order to run this notebook yourself, you will need the following:\n",
    "\n",
    "- This notebook. If you are viewing this in the HTML documentation bundle, you can download all of the example notebooks and supporting materials from [Downloads](../index.rst).\n",
    "- The required dataset, which is included in the same directory as this notebook.\n",
    "- A DataRobot API token. You can find your API token by logging into the DataRobot Web User Interface and looking in your `Profile`.\n",
    "\n",
    "\n",
    "### Installing the `datarobot` package\n",
    "The `datarobot` package is hosted on PyPI. You can install it via:\n",
    "```\n",
    "pip install datarobot\n",
    "```\n",
    "from the command line. Its main dependencies are `numpy` and `pandas`, which could take some time to install on a new system. We highly recommend use of virtualenvs to avoid conflicts with other dependencies in your system-wide python installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "This line imports the `datarobot` package. By convention, we always import it with the alias `dr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Important Imports\n",
    "We'll use these in this notebook as well. If the previous cell and the following\n",
    "cell both run without issue, you're in good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Python Client\n",
    "Configuring the client requires the following two things:\n",
    "\n",
    "- A DataRobot endpoint - where the API server can be found\n",
    "- A DataRobot API token - a token the server uses to identify and validate the user making API requests\n",
    "\n",
    "The endpoint is usually the URL you would use to log into the DataRobot Web User Interface (e.g., https://app.datarobot.com) with \"/api/v2/\" appended, e.g., (https://app.datarobot.com/api/v2/).\n",
    "\n",
    "You can find your API token by logging into the DataRobot Web User Interface and looking in your `Profile.`\n",
    "\n",
    "The Python client can be configured in several ways. The example we'll use in this notebook is to point to a `yaml` file that has the information. This is a text file containing two lines like this:\n",
    "```yaml\n",
    "endpoint: https://app.datarobot.com/api/v2/\n",
    "token: not-my-real-token\n",
    "```\n",
    "\n",
    "If you want to run this notebook without changes, please save your configuration in a file located under your home directory called `~/.config/datarobot/drconfig.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x11043b210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization with arguments\n",
    "# dr.Client(token='<API TOKEN>', endpoint='https://<YOUR ENDPOINT>/api/v2/')\n",
    "\n",
    "# Initialization with a config file in the same directory as this notebook\n",
    "# dr.Client(config_path='drconfig.yaml')\n",
    "\n",
    "# Initialization with a config file located at\n",
    "# ~/.config/datarobot/dr.config.yaml\n",
    "dr.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Project\n",
    "Here, we use the `datarobot` package to upload a new file and create a project. The name of the project is optional, but can be helpful when trying to sort among many projects on DataRobot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: 5c007ffa784cc602016a9f06\n"
     ]
    }
   ],
   "source": [
    "filename = '10K_Lending_Club_Loans.csv'\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M')\n",
    "project_name = '10K_Lending_Club_Loans_{}'.format(now)\n",
    "proj = dr.Project.create(sourcedata=filename,\n",
    "                         project_name=project_name)\n",
    "print('Project ID: {}'.format(proj.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features for Modeling\n",
    "First, retrieve the raw feature list. This corresponds to the columns in the input spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funded_amnt</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>term</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>Percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>installment</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grade</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>emp_title</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pymnt_plan</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>url</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>desc</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>purpose</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>title</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zip_code</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dti</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>earliest_cr_line</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mths_since_last_record</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>open_acc</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pub_rec</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>revol_bal</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>revol_util</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>total_acc</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mths_since_last_major_derog</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>policy_code</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>is_bad</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name         type\n",
       "0                     loan_amnt      Numeric\n",
       "1                   funded_amnt      Numeric\n",
       "2                          term  Categorical\n",
       "3                      int_rate   Percentage\n",
       "4                   installment      Numeric\n",
       "5                         grade  Categorical\n",
       "6                     sub_grade  Categorical\n",
       "7                     emp_title         Text\n",
       "8                    emp_length  Categorical\n",
       "9                home_ownership  Categorical\n",
       "10                   annual_inc      Numeric\n",
       "11          verification_status  Categorical\n",
       "12                   pymnt_plan  Categorical\n",
       "13                          url         Text\n",
       "14                         desc         Text\n",
       "15                      purpose  Categorical\n",
       "16                        title         Text\n",
       "17                     zip_code  Categorical\n",
       "18                   addr_state  Categorical\n",
       "19                          dti      Numeric\n",
       "20                  delinq_2yrs      Numeric\n",
       "21             earliest_cr_line         Date\n",
       "22               inq_last_6mths      Numeric\n",
       "23       mths_since_last_delinq      Numeric\n",
       "24       mths_since_last_record      Numeric\n",
       "25                     open_acc      Numeric\n",
       "26                      pub_rec      Numeric\n",
       "27                    revol_bal      Numeric\n",
       "28                   revol_util      Numeric\n",
       "29                    total_acc      Numeric\n",
       "30          initial_list_status  Categorical\n",
       "31  mths_since_last_major_derog         None\n",
       "32                  policy_code  Categorical\n",
       "33                       is_bad      Numeric"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = [feat_list for feat_list in proj.get_featurelists()\n",
    "       if feat_list.name == 'Raw Features'][0]\n",
    "raw_features = [\n",
    "    {\n",
    "        \"name\": feat,\n",
    "        \"type\": dr.Feature.get(proj.id, feat).feature_type\n",
    "    }\n",
    "    for feat in raw.features\n",
    "]\n",
    "pd.DataFrame.from_dict(raw_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Feature Types\n",
    "We can tweak features to improve the modeling. For example, we might change `delinq_2yrs` from an integer into a categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(delinq_2yrs(Cat))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.create_type_transform_feature(\n",
    "    \"delinq_2yrs(Cat)\",  # new feature name\n",
    "    \"delinq_2yrs\",       # parent name\n",
    "    dr.enums.VARIABLE_TYPE_TRANSFORM.CATEGORICAL_INT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can change type of `addr_state` from categorical into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(addr_state(Text))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.create_type_transform_feature(\n",
    "    \"addr_state(Text)\",  # new feature name\n",
    "    \"addr_state\",        # parent name\n",
    "    dr.enums.VARIABLE_TYPE_TRANSFORM.TEXT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features for Modeling\n",
    "Next, we create a new feature list where we remove the features `delinq_2yrs` and `addr_state` and add the modified features we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_name = \"new_feature_list\"\n",
    "\n",
    "new_feature_list = proj.create_featurelist(\n",
    "    feature_list_name,\n",
    "    list((set(raw.features) - {\"addr_state\", \"delinq_2yrs\"}) |\n",
    "         {\"addr_state(Text)\", \"delinq_2yrs(Cat)\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Automated Modeling Process\n",
    "Now we can start the modeling process. The target for this problem is called `is_bad` - a binary variable indicating whether or not the customer defaults on a particular loan.\n",
    "\n",
    "We specify that the metric that should be used is `LogLoss`. Without a specification DataRobot would automatically select an appropriate default metric.\n",
    "\n",
    "The `featurelist_id` parameter tells DataRobot to model on that specific featurelist, rather than the default `Informative Features`.\n",
    "\n",
    "Finally, the `worker_count` parameter specifies how many workers should be used for this project. Passing a value of `-1` tells DataRobot to set the worker count to the maximum available to you. You can also specify the exact number of workers to use, but this command will fail if you request more workers than your account allows. If you need more resources than what has been allocated to you, you should think about upgrading your license.\n",
    "\n",
    "The last command in this cell is just a blocking loop that periodically checks on the project to see if it is done, printing out the number of jobs in progress and in the queue along the way so you can see progress. The automated model exploration process will occasionally add more jobs to the queue, so don't be alarmed if the number of jobs does not strictly decrease over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: 17, queued: 21 (waited: 0s)\n",
      "In progress: 20, queued: 18 (waited: 1s)\n",
      "In progress: 20, queued: 18 (waited: 2s)\n",
      "In progress: 20, queued: 18 (waited: 3s)\n",
      "In progress: 19, queued: 18 (waited: 5s)\n",
      "In progress: 20, queued: 17 (waited: 7s)\n",
      "In progress: 20, queued: 16 (waited: 12s)\n",
      "In progress: 20, queued: 12 (waited: 19s)\n",
      "In progress: 19, queued: 8 (waited: 32s)\n",
      "In progress: 20, queued: 2 (waited: 53s)\n",
      "In progress: 16, queued: 0 (waited: 74s)\n",
      "In progress: 16, queued: 0 (waited: 95s)\n",
      "In progress: 16, queued: 0 (waited: 115s)\n",
      "In progress: 16, queued: 0 (waited: 136s)\n",
      "In progress: 15, queued: 0 (waited: 156s)\n",
      "In progress: 13, queued: 0 (waited: 177s)\n",
      "In progress: 8, queued: 0 (waited: 198s)\n",
      "In progress: 1, queued: 0 (waited: 218s)\n",
      "In progress: 19, queued: 0 (waited: 238s)\n",
      "In progress: 13, queued: 0 (waited: 259s)\n",
      "In progress: 6, queued: 0 (waited: 280s)\n",
      "In progress: 2, queued: 0 (waited: 300s)\n",
      "In progress: 13, queued: 0 (waited: 321s)\n",
      "In progress: 9, queued: 0 (waited: 341s)\n",
      "In progress: 6, queued: 0 (waited: 362s)\n",
      "In progress: 2, queued: 0 (waited: 382s)\n",
      "In progress: 2, queued: 0 (waited: 403s)\n",
      "In progress: 1, queued: 0 (waited: 423s)\n",
      "In progress: 1, queued: 0 (waited: 444s)\n",
      "In progress: 1, queued: 0 (waited: 464s)\n",
      "In progress: 20, queued: 12 (waited: 485s)\n",
      "In progress: 20, queued: 12 (waited: 505s)\n",
      "In progress: 20, queued: 6 (waited: 526s)\n",
      "In progress: 19, queued: 3 (waited: 547s)\n",
      "In progress: 19, queued: 0 (waited: 567s)\n",
      "In progress: 18, queued: 0 (waited: 588s)\n",
      "In progress: 16, queued: 0 (waited: 609s)\n",
      "In progress: 13, queued: 0 (waited: 629s)\n",
      "In progress: 11, queued: 0 (waited: 650s)\n",
      "In progress: 7, queued: 0 (waited: 670s)\n",
      "In progress: 3, queued: 0 (waited: 691s)\n",
      "In progress: 3, queued: 0 (waited: 711s)\n",
      "In progress: 3, queued: 0 (waited: 732s)\n",
      "In progress: 1, queued: 0 (waited: 752s)\n",
      "In progress: 0, queued: 0 (waited: 773s)\n",
      "In progress: 1, queued: 0 (waited: 793s)\n",
      "In progress: 0, queued: 0 (waited: 814s)\n",
      "In progress: 4, queued: 0 (waited: 834s)\n",
      "In progress: 2, queued: 0 (waited: 855s)\n",
      "In progress: 4, queued: 0 (waited: 875s)\n",
      "In progress: 4, queued: 0 (waited: 895s)\n",
      "In progress: 2, queued: 0 (waited: 916s)\n",
      "In progress: 2, queued: 0 (waited: 936s)\n",
      "In progress: 0, queued: 0 (waited: 957s)\n",
      "In progress: 0, queued: 0 (waited: 977s)\n"
     ]
    }
   ],
   "source": [
    "proj.set_target(\n",
    "    \"is_bad\",\n",
    "    mode=dr.enums.AUTOPILOT_MODE.FULL_AUTO,\n",
    "    metric=\"LogLoss\",\n",
    "    featurelist_id=new_feature_list.id,\n",
    "    worker_count=-1\n",
    ")\n",
    "\n",
    "proj.wait_for_autopilot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Trained Models\n",
    "We can see how many models DataRobot built for this project by querying. Each of them has been tuned individually. Models that appear to have the same name differ either in the amount of data used in training or in the preprocessing steps used (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 0.36614 - ENET Blender\n",
      "[1]: 0.36661 - Advanced AVG Blender\n",
      "[2]: 0.36684 - ENET Blender\n",
      "[3]: 0.36686 - AVG Blender\n",
      "[4]: 0.36712 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[5]: 0.36787 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[6]: 0.36791 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[7]: 0.36839 - Light Gradient Boosted Trees Classifier with Early Stopping\n",
      "[8]: 0.3684 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[9]: 0.36872 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[10]: 0.36873 - Generalized Additive2 Model\n",
      "[11]: 0.36938 - Generalized Additive2 Model\n",
      "[12]: 0.36952 - RandomForest Classifier (Gini)\n",
      "[13]: 0.36971 - Light Gradient Boosted Trees Classifier with Early Stopping\n",
      "[14]: 0.36978 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[15]: 0.37004 - RandomForest Classifier (Entropy)\n",
      "[16]: 0.37073 - RandomForest Classifier (Gini)\n",
      "[17]: 0.37121 - Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)\n",
      "[18]: 0.37235 - Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)\n",
      "[19]: 0.37274 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[20]: 0.37275 - Vowpal Wabbit Classifier\n",
      "[21]: 0.37283 - RandomForest Classifier (Entropy)\n",
      "[22]: 0.37302 - ExtraTrees Classifier (Gini)\n",
      "[23]: 0.37335 - Vowpal Wabbit Classifier\n",
      "[24]: 0.37345 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[25]: 0.37357 - Nystroem Kernel SVM Classifier\n",
      "[26]: 0.37362 - Nystroem Kernel SVM Classifier\n",
      "[27]: 0.37368 - ExtraTrees Classifier (Gini)\n",
      "[28]: 0.37417 - Gradient Boosted Trees Classifier with Early Stopping\n",
      "[29]: 0.37495 - Gradient Boosted Trees Classifier with Early Stopping\n",
      "[30]: 0.37548 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[31]: 0.37574 - Regularized Logistic Regression (L2)\n",
      "[32]: 0.37607 - RandomForest Classifier (Gini)\n",
      "[33]: 0.37631 - Vowpal Wabbit Classifier\n",
      "[34]: 0.37667 - Light Gradient Boosted Trees Classifier with Early Stopping\n",
      "[35]: 0.37767 - Generalized Additive2 Model\n",
      "[36]: 0.37773 - Regularized Logistic Regression (L2)\n",
      "[37]: 0.37814 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[38]: 0.37816 - Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)\n",
      "[39]: 0.37862 - RandomForest Classifier (Entropy)\n",
      "[40]: 0.37921 - Elastic-Net Classifier (L2 / Binomial Deviance) with Binned numeric features\n",
      "[41]: 0.37929 - Regularized Logistic Regression (L2)\n",
      "[42]: 0.37953 - Auto-tuned K-Nearest Neighbors Classifier (Euclidean Distance)\n",
      "[43]: 0.38011 - Regularized Logistic Regression (L2)\n",
      "[44]: 0.38013 - Elastic-Net Classifier (L2 / Binomial Deviance)\n",
      "[45]: 0.38024 - Eureqa Generalized Additive Model Classifier (3000 Generations)\n",
      "[46]: 0.38026 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - desc\n",
      "[47]: 0.38037 - Gradient Boosted Trees Classifier\n",
      "[48]: 0.38127 - Gradient Boosted Trees Classifier\n",
      "[49]: 0.3813 - Light Gradient Boosting on ElasticNet Predictions \n",
      "[50]: 0.38136 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - desc\n",
      "[51]: 0.38176 - Elastic-Net Classifier (L2 / Binomial Deviance) with Binned numeric features\n",
      "[52]: 0.38236 - eXtreme Gradient Boosted Trees Classifier with Early Stopping and Unsupervised Learning Features\n",
      "[53]: 0.38237 - eXtreme Gradient Boosted Trees Classifier with Early Stopping\n",
      "[54]: 0.3833 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - title\n",
      "[55]: 0.38354 - Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance) with Unsupervised Learning Features\n",
      "[56]: 0.38373 - Elastic-Net Classifier (L2 / Binomial Deviance)\n",
      "[57]: 0.38387 - Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)\n",
      "[58]: 0.38401 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - emp_title\n",
      "[59]: 0.38428 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - emp_title\n",
      "[60]: 0.38435 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - emp_title\n",
      "[61]: 0.38481 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - title\n",
      "[62]: 0.38497 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - title\n",
      "[63]: 0.38505 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - addr_state(Text)\n",
      "[64]: 0.38524 - RandomForest Classifier (Gini)\n",
      "[65]: 0.38532 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - title\n",
      "[66]: 0.38572 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - addr_state(Text)\n",
      "[67]: 0.38606 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - desc\n",
      "[68]: 0.38639 - Majority Class Classifier\n",
      "[69]: 0.38642 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - url\n",
      "[70]: 0.38662 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - url\n",
      "[71]: 0.387 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - addr_state(Text)\n",
      "[72]: 0.38711 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - desc\n",
      "[73]: 0.38726 - Regularized Logistic Regression (L2)\n",
      "[74]: 0.38738 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - url\n",
      "[75]: 0.38802 - Auto-Tuned Word N-Gram Text Modeler using token occurrences - addr_state(Text)\n",
      "[76]: 0.39071 - Gradient Boosted Greedy Trees Classifier with Early Stopping\n",
      "[77]: 0.40035 - Auto-tuned K-Nearest Neighbors Classifier (Euclidean Distance)\n",
      "[78]: 0.40057 - Breiman and Cutler Random Forest Classifier\n",
      "[79]: 0.41186 - RuleFit Classifier\n",
      "[80]: 0.43793 - Naive Bayes combiner classifier\n",
      "[81]: 0.44045 - Auto-tuned K-Nearest Neighbors Classifier (Euclidean Distance)\n",
      "[82]: 0.44713 - Logistic Regression\n",
      "[83]: 0.48423 - Decision Tree Classifier (Gini)\n",
      "[84]: 0.60431 - TensorFlow Neural Network Classifier\n"
     ]
    }
   ],
   "source": [
    "models = proj.get_models()\n",
    "for idx, model in enumerate(models):\n",
    "    print('[{}]: {} - {}'.\n",
    "          format(idx, model.metrics['LogLoss']['validation'],\n",
    "                 model.model_type))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions\n",
    "\n",
    "### Predictions: modeling workers vs. dedicated servers\n",
    "There are two ways to generate predictions in DataRobot: using modeling workers and dedicated prediction servers. In this notebook we will use the former, which is slower, occupies one of your modeling worker slots, and has no strong latency guarantees because the jobs go through the project queue. This method can be useful for developing and evaluating models. However, in a production environment, a faster, dedicated prediction server configuration may be more appropriate.\n",
    "\n",
    "### Three step process\n",
    "As just mentioned, these predictions go through the modeling queue, so there is a three-step process. The first step is to upload your dataset; the second is to generate prediction jobs. Finally, you need to retreive your predictions when the job is done.\n",
    "\n",
    "To simplify this example we will make predictions for the same data used to train the models. We could use any of the models DataRobot generated, but will select the model that DataRobot recommends for deployment. DataRobot weighs both model accuracy and runtime to develop this recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = proj.upload_dataset(filename)\n",
    "\n",
    "model = dr.ModelRecommendation.get(\n",
    "    proj.id,\n",
    "    dr.enums.RECOMMENDED_MODEL_TYPE.RECOMMENDED_FOR_DEPLOYMENT\n",
    ").get_model()\n",
    "\n",
    "pred_job = model.request_predictions(dataset.id)\n",
    "preds = pred_job.get_result_when_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "This example is a binary, or two-class classification problem, so DataRobot estimates the probability of each row is in the positive class (a bad loan) and negative class (not a bad loan). `positive_probability` and `class_1.0` represent the former, and `class_0.0` the latter. Given a configurable `prediction_threshold`, DataRobot creates a `prediction` whose value is the predicted class for each row. The predictions can be matched to the the uploaded prediction data set through the `row_id` predictions field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_threshold</th>\n",
       "      <th>row_id</th>\n",
       "      <th>class_0.0</th>\n",
       "      <th>class_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907323</td>\n",
       "      <td>0.092677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738097</td>\n",
       "      <td>0.261903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.904413</td>\n",
       "      <td>0.095587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.878498</td>\n",
       "      <td>0.121502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934018</td>\n",
       "      <td>0.065982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive_probability  prediction  prediction_threshold  row_id  class_0.0  \\\n",
       "0              0.092677         0.0                   0.5       0   0.907323   \n",
       "1              0.261903         0.0                   0.5       1   0.738097   \n",
       "2              0.095587         0.0                   0.5       2   0.904413   \n",
       "3              0.121502         0.0                   0.5       3   0.878498   \n",
       "4              0.065982         0.0                   0.5       4   0.934018   \n",
       "\n",
       "   class_1.0  \n",
       "0   0.092677  \n",
       "1   0.261903  \n",
       "2   0.095587  \n",
       "3   0.121502  \n",
       "4   0.065982  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
