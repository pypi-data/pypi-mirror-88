# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.

import scrapy

from lich_scrapy_extracts_pipeline.items import ExampleItem


class ExampleSpider(scrapy.Spider):
    """ ExampleSpider
    Auto generated by os-scrapy-cookiecuter

    Run:
        scrapy crawl example
    """

    name = "example"

    def start_requests(self):
        yield scrapy.Request(
            # url="https://upload.wikimedia.org/wikipedia/commons/0/03/Joe_Biden_2013.jpg",
            url="https://www.example.com/",
            meta={
                "extractor2.kafka.topic": "test_topic",
                "extractor2.kafka.brokers": "test:9092",
                "extractor2.extracts": {"a": "n"},
            },
        )

    def parse(self, response):
        yield ExampleItem(
            url=response.url,
            request_headers=response.request.headers,
            response_headers=response.headers,
            status=response.status,
            meta=response.meta,
            body=response.body,
        )
