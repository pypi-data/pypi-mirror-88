# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['gym_chess', 'gym_chess.alphazero', 'gym_chess.alphazero.move_encoding']

package_data = \
{'': ['*']}

install_requires = \
['gym>=0.17.2,<0.18.0', 'python-chess>=0.31.1,<0.32.0']

setup_kwargs = {
    'name': 'gym-chess',
    'version': '0.1.1',
    'description': 'OpenAI Gym environments for Chess',
    'long_description': "# gym-chess: OpenAI Gym environments for Chess\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Installation](#installation)\n3. [Chess-v0](#chess-v0)\n4. [ChessAlphaZero-v0](#chessalphazero-v0)\n5. [Acknowledgements](#acknowledgements)\n\n## Introduction\n\ngym-chess provides [OpenAI Gym](https://gym.openai.com) environments for the \ngame of Chess. It comes with an implementation of the board and move \nencoding used in [AlphaZero](https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go), \nyet leaves you the freedom to define your own encodings via wrappers.\n\nLet's watch a random agent play against itself:\n\n```python\n>>> import gym\n>>> import gym_chess\n>>> import random\n\n>>> env = gym.make('Chess-v0')\n>>> print(env.render())\n\n>>> env.reset()\n>>> done = False\n\n>>> while not done:\n>>>     action = random.sample(env.legal_moves)\n>>>     env.step(action)\n>>>     print(env.render(mode='unicode'))\n\n>>> env.close()\n```\n\n## Installation\n\ngym-chess requires Python 3.6 or later.\n\nTo install gym-chess, run:\n\n```shell\n$ pip install gym-chess\n```\n\nImporting gym-chess will automatically register the `Chess-v0` and \n`ChessAlphaZero-v0` envs with gym:\n\n```python\n>>> import gym\n>>> import gym_chess\n\n>>> gym.envs.registry.all()\ndict_values([... EnvSpec(Chess-v0), EnvSpec(ChessAlphaZero-v0)])\n```\n\n\n## Chess-v0\n\ngym-chess defines a basic `Chess-v0` environment which represents \nobservations and actions as objects of type `chess.Board` and `chess.Move`, \nrespectively. These classes come from the\n[python-chess](https://github.com/niklasf/python-chess) package which implements\nthe game logic.\n\n```python\n\n>>> env = gym.make('Chess-v0')\n>>> state = env.reset()\n>>> type(state)\nchess.Board\n\n>>> print(env.render(mode='unicode'))\n♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜\n♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙\n♖ ♘ ♗ ♕ ♔ ♗ ♘ ♖\n\n>>> move = chess.Move.from_uci('e2e4')\n>>> env.step(move)\n>>> print(env.render(mode='unicode'))\n♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜\n♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ♙ ⭘ ⭘ ⭘\n⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘ ⭘\n♙ ♙ ♙ ♙ ⭘ ♙ ♙ ♙\n♖ ♘ ♗ ♕ ♔ ♗ ♘ ♖\n\n```\n\nA list of legal moves for the current position is exposed via the `legal_moves`\nproperty:\n\n```\n>>> env.reset()\n>>> env.legal_moves\n[Move.from_uci('g1h3'),\n Move.from_uci('g1f3'),\n Move.from_uci('b1c3'),\n Move.from_uci('b1a3'),\n Move.from_uci('h2h3'),\n Move.from_uci('g2g3'),\n Move.from_uci('f2f3'),\n Move.from_uci('e2e3'),\n Move.from_uci('d2d3'),\n Move.from_uci('c2c3'),\n Move.from_uci('b2b3'),\n Move.from_uci('a2a3'),\n Move.from_uci('h2h4'),\n Move.from_uci('g2g4'),\n Move.from_uci('f2f4'),\n Move.from_uci('e2e4'),\n Move.from_uci('d2d4'),\n Move.from_uci('c2c4'),\n Move.from_uci('b2b4'),\n Move.from_uci('a2a4')]\n\n```\n\nUsing ordinary Python objects (rather than NumPy arrays) as an agent interface \nis arguably unorthodox. An immideate consequence of this approach is that \n`Chess-v0` has no well-defined `observation_space` and `action_space`; hence \nthese member variables are set to `None`. However, this design allows us to \nseperate the game's _implementation_ from its _representation_, which is left to \nwrapper classes.\n\n\nThe agent plays for both players, black **and** white, by making moves\nfor either color in turn. An episode ends when a player wins (i.e. the agent\nmakes a move that puts the opponent player into checkmate), or the game results \nin a draw (e.g. by reaching a stalemate position, insufficient material, or one\nor more other draw conditions according to the \n[FIDE Rules of Chess](https://en.wikipedia.org/wiki/Rules_of_chess)). \nNote that there is currently no option for the agent to let a player resign or\noffer a draw voluntarily.\n\nThe agent receives a reward of +1 when the white player makes a winning move,\nand a reward of -1 when the black player makes a winning move. All other rewards\nare zero.\n\n\n## ChessAlphaZero-v0\n\ngym-chess ships with an implementation of the board and move encoding proposed \nby [AlphaZero]() (see [Silver et al., 2017]()).\n\n```python\n>>> env = gym.make('ChessAlphaZero-v0')\n>>> env.observation_space\nBox(8, 8, 119)\n\n>>> env.action_space\nDiscrete(4672)\n```\n\nFor a detailed description of how these encodings work, consider reading the \npaper or consult the docstring of the respective classes.\n\nIn addition to `legal_moves`, ChessAlphaZero-v0 also exposes a list of all\nlegal actions (i.e. encoded legal moves):\n\n```python\n>>> env.legal_actions\n[494,\n 501,\n 129,\n 136,\n 1095,\n 1022,\n 949,\n 876,\n 803,\n 730,\n 657,\n 584,\n 1096,\n 1023,\n 950,\n 877,\n 804,\n 731,\n 658,\n 585]\n```\n\nMoves can be converted to actions and vice versawith the `encode` and `decode` \nmethods, which may facilitate debugging and experimentation:\n\n```\n>>> move = chess.Move.from_uci('e2e4')\n>>> env.encode(move)\n877\n>>> env.encode(move) in env.legal_actions\nTrue\n\n>>> env.decode(877)\nMove.from_uci('e2e4')\n```\n\nInternally, the encoding is implemented via wrapper classes \n(`gym_chess.alphazero.BoardEncoding` and `gym_chess.alphazero.MoveEncoding`,\nrespectively), which can be used independently of one another. This gives you \nthe flexibility to define your own board and move representations, and easily\nswitch between them.\n\n```python\n>>> import gym_chess\n>>> from gym_chess.alphazero import BoardEncoding\n\n>>> env = gym.make('Chess-v0')\n>>> env = BoardEncoding(env, history_length=4)\n>>> env = MyEsotericMoveEncoding(env)\n```\n\n\n## Acknowledgements\n\nThanks to @niklasf for providing the awesome \n[python-chess](https://github.com/niklasf/python-chess) package.\n",
    'author': 'Lucas Wolf',
    'author_email': 'iamlucaswolf@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/iamlucaswolf/gym-chess',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
